{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLtrkDgkPeo-"
      },
      "source": [
        "# Reconnaissance Automatique d'Événements dans des Textes\n",
        "\n",
        "Ce notebook permet d'exécuter le pipeline complet de reconnaissance d'événements en utilisant des modèles BERT fine-tunés. Il est conçu pour fonctionner avec des annotations au format WebAnno TSV 3.3.\n",
        "\n",
        "## Types d'événements reconnus\n",
        "- Conflit\n",
        "- Décision gouvernementale\n",
        "- Décès\n",
        "- Avancée technologique\n",
        "- Événement culturel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do-wxTynPmoo",
        "outputId": "6bd12293-bdf7-4373-e13b-8854b3dba8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya4i-piWPepD"
      },
      "source": [
        "## 1. Configuration de l'environnement\n",
        "\n",
        "### 1.1 Monter Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GBxEY75PepF",
        "outputId": "be5fe986-4e72-468a-877d-304f424678fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Définir le chemin vers le dossier d'annotations\n",
        "# Modifiez ce chemin selon l'emplacement de votre dossier dans Drive\n",
        "ANNOTATIONS_DIR = '/content/drive/MyDrive/annotation'\n",
        "\n",
        "# Créer un dossier pour les sorties\n",
        "OUTPUT_DIR = '/content/output'\n",
        "!mkdir -p {OUTPUT_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6H4_NtPepH"
      },
      "source": [
        "### 1.2 Installation des dépendances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH48-s8VPepI",
        "outputId": "a0537665-aa3a-478d-d4f0-d3fc5d7472aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torchcrf\n",
            "  Downloading TorchCRF-1.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading TorchCRF-1.1.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, torchcrf\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchcrf-1.1.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch torchcrf scikit-learn matplotlib seaborn pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==3.5.0 torchcrf==1.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKLMIRK7Q2Ut",
        "outputId": "5f94c6b9-7645-47c6-c650-dd2b4414f1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets==3.5.0 in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: torchcrf==1.1.0 in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchcrf==1.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->torchcrf==1.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->torchcrf==1.1.0) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->torchcrf==1.1.0) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSgvZIj8PepJ"
      },
      "source": [
        "## 2. Implémentation des modules\n",
        "\n",
        "### 2.1 Module de prétraitement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZudKUy7PepL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple, Set, Optional\n",
        "import glob\n",
        "\n",
        "# Définition des types d'événements\n",
        "EVENT_TYPES = [\n",
        "    \"conflit\",\n",
        "    \"décision gouvernementale\",\n",
        "    \"décès\",\n",
        "    \"avancée technologique\",\n",
        "    \"événement culturel\"\n",
        "]\n",
        "\n",
        "class TSVAnnotationParser:\n",
        "    \"\"\"\n",
        "    Classe pour parser les fichiers d'annotation au format WebAnno TSV 3.3\n",
        "    et extraire les annotations d'événements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, event_types: List[str] = EVENT_TYPES):\n",
        "        \"\"\"\n",
        "        Initialise le parser avec les types d'événements à reconnaître.\n",
        "\n",
        "        Args:\n",
        "            event_types: Liste des types d'événements à reconnaître\n",
        "        \"\"\"\n",
        "        self.event_types = event_types\n",
        "\n",
        "    def parse_tsv_file(self, file_path: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Parse un fichier TSV et extrait le texte et les annotations.\n",
        "\n",
        "        Args:\n",
        "            file_path: Chemin vers le fichier TSV\n",
        "\n",
        "        Returns:\n",
        "            Un dictionnaire contenant le texte et les annotations\n",
        "        \"\"\"\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Extraire l'en-tête et le format\n",
        "        header = []\n",
        "        i = 0\n",
        "        while i < len(lines) and not lines[i].startswith('#Text='):\n",
        "            header.append(lines[i].strip())\n",
        "            i += 1\n",
        "\n",
        "        # Initialiser les structures de données\n",
        "        sentences = []\n",
        "        current_sentence = {'text': '', 'tokens': [], 'annotations': []}\n",
        "\n",
        "        # Parser le contenu\n",
        "        while i < len(lines):\n",
        "            line = lines[i].strip()\n",
        "\n",
        "            # Nouvelle phrase\n",
        "            if line.startswith('#Text='):\n",
        "                if current_sentence['tokens']:\n",
        "                    sentences.append(current_sentence)\n",
        "                    current_sentence = {'text': '', 'tokens': [], 'annotations': []}\n",
        "\n",
        "                current_sentence['text'] = line[6:]  # Extraire le texte après '#Text='\n",
        "\n",
        "            # Ligne de token\n",
        "            elif line and not line.startswith('#'):\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) >= 3:  # Au moins l'ID, les positions et le texte\n",
        "                    token_id = parts[0]\n",
        "                    token_span = parts[1]\n",
        "                    token_text = parts[2]\n",
        "\n",
        "                    # Extraire les annotations d'événements si présentes\n",
        "                    event_annotation = None\n",
        "                    if len(parts) >= 4 and parts[3] != '_':\n",
        "                        # Vérifier si l'annotation contient un indice (ex: \"Décision gouvernementale[1]\")\n",
        "                        match = re.match(r'(.+?)(?:\\[(\\d+)\\])?$', parts[3])\n",
        "                        if match:\n",
        "                            event_type = match.group(1)\n",
        "                            event_index = match.group(2)\n",
        "\n",
        "                            if event_type in self.event_types:\n",
        "                                event_annotation = {\n",
        "                                    'type': event_type,\n",
        "                                    'index': int(event_index) if event_index else None\n",
        "                                }\n",
        "\n",
        "                    # Ajouter le token et son annotation\n",
        "                    token_info = {\n",
        "                        'id': token_id,\n",
        "                        'span': token_span,\n",
        "                        'text': token_text,\n",
        "                        'event': event_annotation\n",
        "                    }\n",
        "                    current_sentence['tokens'].append(token_info)\n",
        "\n",
        "                    # Si le token a une annotation, l'ajouter à la liste des annotations\n",
        "                    if event_annotation:\n",
        "                        start, end = map(int, token_span.split('-'))\n",
        "                        annotation = {\n",
        "                            'token_id': token_id,\n",
        "                            'start': start,\n",
        "                            'end': end,\n",
        "                            'text': token_text,\n",
        "                            'type': event_annotation['type'],\n",
        "                            'index': event_annotation['index']\n",
        "                        }\n",
        "                        current_sentence['annotations'].append(annotation)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        # Ajouter la dernière phrase\n",
        "        if current_sentence['tokens']:\n",
        "            sentences.append(current_sentence)\n",
        "\n",
        "        # Regrouper les annotations multi-tokens\n",
        "        for sentence in sentences:\n",
        "            self._group_multi_token_annotations(sentence)\n",
        "\n",
        "        return {\n",
        "            'header': header,\n",
        "            'sentences': sentences\n",
        "        }\n",
        "\n",
        "    def _group_multi_token_annotations(self, sentence: Dict) -> None:\n",
        "        \"\"\"\n",
        "        Regroupe les annotations qui s'étendent sur plusieurs tokens.\n",
        "\n",
        "        Args:\n",
        "            sentence: Dictionnaire contenant les informations d'une phrase\n",
        "        \"\"\"\n",
        "        # Regrouper par index d'annotation\n",
        "        grouped_annotations = defaultdict(list)\n",
        "\n",
        "        for annotation in sentence['annotations']:\n",
        "            if annotation['index'] is not None:\n",
        "                key = (annotation['type'], annotation['index'])\n",
        "                grouped_annotations[key].append(annotation)\n",
        "            else:\n",
        "                # Les annotations sans index sont déjà des entités complètes\n",
        "                key = (annotation['type'], f\"single_{annotation['token_id']}\")\n",
        "                grouped_annotations[key].append(annotation)\n",
        "\n",
        "        # Créer des annotations multi-tokens\n",
        "        multi_token_annotations = []\n",
        "\n",
        "        for (event_type, _), annotations in grouped_annotations.items():\n",
        "            if len(annotations) > 0:\n",
        "                # Trier par position de début\n",
        "                sorted_annotations = sorted(annotations, key=lambda x: x['start'])\n",
        "\n",
        "                # Créer une annotation multi-tokens\n",
        "                start = sorted_annotations[0]['start']\n",
        "                end = sorted_annotations[-1]['end']\n",
        "                text = ' '.join(a['text'] for a in sorted_annotations)\n",
        "                token_ids = [a['token_id'] for a in sorted_annotations]\n",
        "\n",
        "                multi_token_annotation = {\n",
        "                    'token_ids': token_ids,\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'text': text,\n",
        "                    'type': event_type\n",
        "                }\n",
        "\n",
        "                multi_token_annotations.append(multi_token_annotation)\n",
        "\n",
        "        # Remplacer les annotations\n",
        "        sentence['multi_token_annotations'] = multi_token_annotations\n",
        "\n",
        "\n",
        "class BIOConverter:\n",
        "    \"\"\"\n",
        "    Classe pour convertir les annotations en format BIO (Beginning, Inside, Outside).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, event_types: List[str] = EVENT_TYPES):\n",
        "        \"\"\"\n",
        "        Initialise le convertisseur avec les types d'événements à reconnaître.\n",
        "\n",
        "        Args:\n",
        "            event_types: Liste des types d'événements à reconnaître\n",
        "        \"\"\"\n",
        "        self.event_types = event_types\n",
        "\n",
        "    def convert_to_bio(self, parsed_data: Dict) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Convertit les annotations en format BIO.\n",
        "\n",
        "        Args:\n",
        "            parsed_data: Données parsées par TSVAnnotationParser\n",
        "\n",
        "        Returns:\n",
        "            Liste de dictionnaires contenant les tokens et leurs tags BIO\n",
        "        \"\"\"\n",
        "        bio_sentences = []\n",
        "\n",
        "        for sentence in parsed_data['sentences']:\n",
        "            bio_sentence = {\n",
        "                'text': sentence['text'],\n",
        "                'tokens': [],\n",
        "                'bio_tags': []\n",
        "            }\n",
        "\n",
        "            # Initialiser tous les tokens comme \"O\" (Outside)\n",
        "            for token in sentence['tokens']:\n",
        "                bio_sentence['tokens'].append(token['text'])\n",
        "                bio_sentence['bio_tags'].append('O')\n",
        "\n",
        "            # Mettre à jour les tags pour les annotations multi-tokens\n",
        "            for annotation in sentence.get('multi_token_annotations', []):\n",
        "                event_type = annotation['type']\n",
        "                token_ids = annotation['token_ids']\n",
        "\n",
        "                # Convertir les IDs de tokens en indices (0-based)\n",
        "                token_indices = []\n",
        "                for token_id in token_ids:\n",
        "                    for i, token in enumerate(sentence['tokens']):\n",
        "                        if token['id'] == token_id:\n",
        "                            token_indices.append(i)\n",
        "                            break\n",
        "\n",
        "                # Assigner les tags B et I\n",
        "                for i, idx in enumerate(token_indices):\n",
        "                    if i == 0:\n",
        "                        bio_sentence['bio_tags'][idx] = f'B-{event_type}'\n",
        "                    else:\n",
        "                        bio_sentence['bio_tags'][idx] = f'I-{event_type}'\n",
        "\n",
        "            bio_sentences.append(bio_sentence)\n",
        "\n",
        "        return bio_sentences\n",
        "\n",
        "\n",
        "class DatasetBuilder:\n",
        "    \"\"\"\n",
        "    Classe pour construire un dataset à partir des annotations au format BIO.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, event_types: List[str] = EVENT_TYPES):\n",
        "        \"\"\"\n",
        "        Initialise le builder avec les types d'événements à reconnaître.\n",
        "\n",
        "        Args:\n",
        "            event_types: Liste des types d'événements à reconnaître\n",
        "        \"\"\"\n",
        "        self.event_types = event_types\n",
        "        self.parser = TSVAnnotationParser(event_types)\n",
        "        self.converter = BIOConverter(event_types)\n",
        "\n",
        "    def build_from_directory(self, directory: str, pattern: str = \"*/MBY3.tsv\") -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Construit un dataset à partir des fichiers TSV dans un répertoire.\n",
        "\n",
        "        Args:\n",
        "            directory: Chemin vers le répertoire contenant les fichiers TSV\n",
        "            pattern: Pattern pour trouver les fichiers TSV (par défaut: \"*/MBY3.tsv\")\n",
        "\n",
        "        Returns:\n",
        "            Liste de dictionnaires contenant les phrases et leurs annotations BIO\n",
        "        \"\"\"\n",
        "        dataset = []\n",
        "\n",
        "        # Trouver tous les fichiers TSV correspondant au pattern\n",
        "        tsv_files = glob.glob(os.path.join(directory, pattern))\n",
        "\n",
        "        for tsv_file in tsv_files:\n",
        "            # Parser le fichier TSV\n",
        "            parsed_data = self.parser.parse_tsv_file(tsv_file)\n",
        "\n",
        "            # Convertir en format BIO\n",
        "            bio_sentences = self.converter.convert_to_bio(parsed_data)\n",
        "\n",
        "            # Ajouter au dataset\n",
        "            for bio_sentence in bio_sentences:\n",
        "                dataset.append({\n",
        "                    'file': tsv_file,\n",
        "                    'text': bio_sentence['text'],\n",
        "                    'tokens': bio_sentence['tokens'],\n",
        "                    'bio_tags': bio_sentence['bio_tags']\n",
        "                })\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    def split_dataset(self, dataset: List[Dict], train_ratio: float = 0.7, val_ratio: float = 0.15,\n",
        "                     test_ratio: float = 0.15, random_seed: int = 42) -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
        "        \"\"\"\n",
        "        Divise le dataset en ensembles d'entraînement, de validation et de test.\n",
        "\n",
        "        Args:\n",
        "            dataset: Liste de dictionnaires contenant les phrases et leurs annotations BIO\n",
        "            train_ratio: Proportion de données pour l'entraînement\n",
        "            val_ratio: Proportion de données pour la validation\n",
        "            test_ratio: Proportion de données pour le test\n",
        "            random_seed: Graine aléatoire pour la reproductibilité\n",
        "\n",
        "        Returns:\n",
        "            Tuple contenant les ensembles d'entraînement, de validation et de test\n",
        "        \"\"\"\n",
        "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-10, \"Les ratios doivent sommer à 1\"\n",
        "\n",
        "        # Mélanger le dataset\n",
        "        np.random.seed(random_seed)\n",
        "        indices = np.random.permutation(len(dataset))\n",
        "\n",
        "        # Calculer les indices de séparation\n",
        "        train_idx = int(len(dataset) * train_ratio)\n",
        "        val_idx = train_idx + int(len(dataset) * val_ratio)\n",
        "\n",
        "        # Diviser le dataset\n",
        "        train_data = [dataset[i] for i in indices[:train_idx]]\n",
        "        val_data = [dataset[i] for i in indices[train_idx:val_idx]]\n",
        "        test_data = [dataset[i] for i in indices[val_idx:]]\n",
        "\n",
        "        return train_data, val_data, test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEH9CxmOPepO"
      },
      "source": [
        "### 2.2 Module de tokenisation et d'encodage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24rrnfrWPepQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class BERTTokenizerForEventRecognition:\n",
        "    \"\"\"\n",
        "    Classe pour tokeniser les textes et aligner les annotations BIO avec les tokens BERT.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"camembert-base\", max_length: int = 128):\n",
        "        \"\"\"\n",
        "        Initialise le tokenizer BERT.\n",
        "\n",
        "        Args:\n",
        "            model_name: Nom du modèle BERT à utiliser\n",
        "            max_length: Longueur maximale des séquences\n",
        "        \"\"\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def tokenize_and_align_labels(self, text: str, tokens: List[str], bio_tags: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Tokenise le texte et aligne les annotations BIO avec les tokens BERT.\n",
        "\n",
        "        Args:\n",
        "            text: Texte brut\n",
        "            tokens: Liste des tokens originaux\n",
        "            bio_tags: Liste des tags BIO correspondant aux tokens originaux\n",
        "\n",
        "        Returns:\n",
        "            Dictionnaire contenant les tokens BERT et les tags BIO alignés\n",
        "        \"\"\"\n",
        "        tokenized_inputs = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "            return_offsets_mapping=True,\n",
        "            return_special_tokens_mask=True,\n",
        "        )\n",
        "\n",
        "        # Créer une liste de tags BIO alignés avec les tokens BERT\n",
        "        aligned_labels = []\n",
        "\n",
        "        # Obtenir les positions des tokens originaux dans le texte\n",
        "        token_positions = []\n",
        "        current_pos = 0\n",
        "        for token in tokens:\n",
        "            start = text.find(token, current_pos)\n",
        "            if start == -1:  # Si le token n'est pas trouvé, essayer avec une recherche moins stricte\n",
        "                for i in range(current_pos, len(text)):\n",
        "                    if text[i:i+len(token)].lower() == token.lower():\n",
        "                        start = i\n",
        "                        break\n",
        "\n",
        "            if start != -1:\n",
        "                end = start + len(token)\n",
        "                token_positions.append((start, end))\n",
        "                current_pos = end\n",
        "            else:\n",
        "                # Si le token n'est toujours pas trouvé, utiliser la position actuelle\n",
        "                token_positions.append((current_pos, current_pos + len(token)))\n",
        "                current_pos += len(token)\n",
        "\n",
        "        # Aligner les tags BIO avec les tokens BERT\n",
        "        offset_mapping = tokenized_inputs.pop(\"offset_mapping\")[0].numpy()\n",
        "        special_tokens_mask = tokenized_inputs.pop(\"special_tokens_mask\")[0].numpy()\n",
        "\n",
        "        for i, (offset_start, offset_end) in enumerate(offset_mapping):\n",
        "            # Ignorer les tokens spéciaux ([CLS], [SEP], etc.)\n",
        "            if special_tokens_mask[i] == 1:\n",
        "                aligned_labels.append(\"O\")\n",
        "                continue\n",
        "\n",
        "            # Trouver le token original qui correspond à ce token BERT\n",
        "            token_idx = None\n",
        "            for j, (token_start, token_end) in enumerate(token_positions):\n",
        "                if offset_start >= token_start and offset_end <= token_end:\n",
        "                    token_idx = j\n",
        "                    break\n",
        "\n",
        "            # Si un token original est trouvé, utiliser son tag BIO\n",
        "            if token_idx is not None:\n",
        "                # Pour les tokens BERT qui sont des sous-mots (commençant par ##),\n",
        "                # utiliser \"I-\" au lieu de \"B-\" s'ils ne sont pas le premier sous-mot\n",
        "                current_tag = bio_tags[token_idx]\n",
        "\n",
        "                # Si ce n'est pas le premier token BERT pour ce token original\n",
        "                # et que le tag commence par \"B-\", le remplacer par \"I-\"\n",
        "                if i > 0 and offset_mapping[i-1][1] > 0 and token_idx == self._find_token_idx(offset_mapping[i-1], token_positions):\n",
        "                    if current_tag.startswith(\"B-\"):\n",
        "                        current_tag = \"I-\" + current_tag[2:]\n",
        "\n",
        "                aligned_labels.append(current_tag)\n",
        "            else:\n",
        "                # Si aucun token original ne correspond, utiliser \"O\"\n",
        "                aligned_labels.append(\"O\")\n",
        "\n",
        "        # Tronquer ou remplir la liste des labels pour qu'elle ait la même longueur que les tokens BERT\n",
        "        if len(aligned_labels) < self.max_length:\n",
        "            aligned_labels.extend([\"O\"] * (self.max_length - len(aligned_labels)))\n",
        "        else:\n",
        "            aligned_labels = aligned_labels[:self.max_length]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": tokenized_inputs[\"input_ids\"][0],\n",
        "            \"attention_mask\": tokenized_inputs[\"attention_mask\"][0],\n",
        "            \"token_type_ids\": tokenized_inputs[\"token_type_ids\"][0],\n",
        "            \"labels\": aligned_labels\n",
        "        }\n",
        "\n",
        "    def _find_token_idx(self, offset: Tuple[int, int], token_positions: List[Tuple[int, int]]) -> Optional[int]:\n",
        "        \"\"\"\n",
        "        Trouve l'indice du token original qui correspond à un offset donné.\n",
        "\n",
        "        Args:\n",
        "            offset: Tuple (start, end) représentant l'offset du token BERT\n",
        "            token_positions: Liste de tuples (start, end) représentant les positions des tokens originaux\n",
        "\n",
        "        Returns:\n",
        "            Indice du token original ou None si aucun ne correspond\n",
        "        \"\"\"\n",
        "        offset_start, offset_end = offset\n",
        "\n",
        "        for i, (token_start, token_end) in enumerate(token_positions):\n",
        "            if offset_start >= token_start and offset_end <= token_end:\n",
        "                return i\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "class EventRecognitionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset PyTorch pour la reconnaissance d'événements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoded_data: List[Dict], label_map: Dict[str, int]):\n",
        "        \"\"\"\n",
        "        Initialise le dataset.\n",
        "\n",
        "        Args:\n",
        "            encoded_data: Liste de dictionnaires contenant les données encodées\n",
        "            label_map: Dictionnaire mappant les tags BIO aux indices numériques\n",
        "        \"\"\"\n",
        "        self.encoded_data = encoded_data\n",
        "        self.label_map = label_map\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Retourne la taille du dataset.\n",
        "\n",
        "        Returns:\n",
        "            Nombre d'exemples dans le dataset\n",
        "        \"\"\"\n",
        "        return len(self.encoded_data)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Retourne un exemple du dataset.\n",
        "\n",
        "        Args:\n",
        "            idx: Indice de l'exemple\n",
        "\n",
        "        Returns:\n",
        "            Dictionnaire contenant les tenseurs pour l'entraînement\n",
        "        \"\"\"\n",
        "        item = self.encoded_data[idx]\n",
        "\n",
        "        # Convertir les labels en indices numériques\n",
        "        labels = [self.label_map.get(label, 0) for label in item[\"labels\"]]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": item[\"input_ids\"],\n",
        "            \"attention_mask\": item[\"attention_mask\"],\n",
        "            \"token_type_ids\": item[\"token_type_ids\"],\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "class BERTDataProcessor:\n",
        "    \"\"\"\n",
        "    Classe pour traiter les données et les préparer pour l'entraînement avec BERT.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"camembert-base\", max_length: int = 128,\n",
        "                event_types: List[str] = EVENT_TYPES):\n",
        "        \"\"\"\n",
        "        Initialise le processeur de données.\n",
        "\n",
        "        Args:\n",
        "            model_name: Nom du modèle BERT à utiliser\n",
        "            max_length: Longueur maximale des séquences\n",
        "            event_types: Liste des types d'événements à reconnaître\n",
        "        \"\"\"\n",
        "        self.tokenizer_wrapper = BERTTokenizerForEventRecognition(model_name, max_length)\n",
        "        self.event_types = event_types\n",
        "\n",
        "        # Créer le mapping des labels\n",
        "        self.label_map = {\"O\": 0}\n",
        "        idx = 1\n",
        "        for event_type in event_types:\n",
        "            self.label_map[f\"B-{event_type}\"] = idx\n",
        "            idx += 1\n",
        "            self.label_map[f\"I-{event_type}\"] = idx\n",
        "            idx += 1\n",
        "\n",
        "        self.id_to_label = {v: k for k, v in self.label_map.items()}\n",
        "\n",
        "    def process_bio_data(self, bio_data: List[Dict]) -> Tuple[EventRecognitionDataset, EventRecognitionDataset, EventRecognitionDataset]:\n",
        "        \"\"\"\n",
        "        Traite les données BIO et crée les datasets pour l'entraînement, la validation et le test.\n",
        "\n",
        "        Args:\n",
        "            bio_data: Liste de dictionnaires contenant les phrases et leurs annotations BIO\n",
        "\n",
        "        Returns:\n",
        "            Tuple contenant les datasets d'entraînement, de validation et de test\n",
        "        \"\"\"\n",
        "        # Encoder les données\n",
        "        encoded_data = []\n",
        "\n",
        "        for item in bio_data:\n",
        "            encoded_item = self.tokenizer_wrapper.tokenize_and_align_labels(\n",
        "                item[\"text\"],\n",
        "                item[\"tokens\"],\n",
        "                item[\"bio_tags\"]\n",
        "            )\n",
        "            encoded_data.append(encoded_item)\n",
        "\n",
        "        # Diviser les données en ensembles d'entraînement, de validation et de test\n",
        "        train_data, temp_data = train_test_split(encoded_data, test_size=0.3, random_state=42)\n",
        "        val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "        # Créer les datasets\n",
        "        train_dataset = EventRecognitionDataset(train_data, self.label_map)\n",
        "        val_dataset = EventRecognitionDataset(val_data, self.label_map)\n",
        "        test_dataset = EventRecognitionDataset(test_data, self.label_map)\n",
        "\n",
        "        return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "    def create_data_loaders(self, train_dataset: EventRecognitionDataset, val_dataset: EventRecognitionDataset,\n",
        "                           test_dataset: EventRecognitionDataset, batch_size: int = 16) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "        \"\"\"\n",
        "        Crée les data loaders pour l'entraînement, la validation et le test.\n",
        "\n",
        "        Args:\n",
        "            train_dataset: Dataset d'entraînement\n",
        "            val_dataset: Dataset de validation\n",
        "            test_dataset: Dataset de test\n",
        "            batch_size: Taille des batchs\n",
        "\n",
        "        Returns:\n",
        "            Tuple contenant les data loaders d'entraînement, de validation et de test\n",
        "        \"\"\"\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "        return train_loader, val_loader, test_loader\n",
        "\n",
        "    def get_label_map(self) -> Dict[str, int]:\n",
        "        \"\"\"\n",
        "        Retourne le mapping des labels.\n",
        "\n",
        "        Returns:\n",
        "            Dictionnaire mappant les tags BIO aux indices numériques\n",
        "        \"\"\"\n",
        "        return self.label_map\n",
        "\n",
        "    def get_id_to_label(self) -> Dict[int, str]:\n",
        "        \"\"\"\n",
        "        Retourne le mapping inverse des labels.\n",
        "\n",
        "        Returns:\n",
        "            Dictionnaire mappant les indices numériques aux tags BIO\n",
        "        \"\"\"\n",
        "        return self.id_to_label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class BERTTokenizerForEventRecognition:\n",
        "    \"\"\"\n",
        "    Classe pour tokeniser les textes et aligner les annotations BIO avec les tokens BERT.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"camembert-base\", max_length: int = 128):\n",
        "        \"\"\"\n",
        "        Initialise le tokenizer BERT.\n",
        "\n",
        "        Args:\n",
        "            model_name: Nom du modèle BERT à utiliser\n",
        "            max_length: Longueur maximale des séquences\n",
        "        \"\"\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def tokenize_and_align_labels(self, text: str, tokens: List[str], bio_tags: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Tokenise le texte et aligne les annotations BIO avec les tokens BERT.\n",
        "\n",
        "        Args:\n",
        "            text: Texte brut\n",
        "            tokens: Liste des tokens originaux\n",
        "            bio_tags: Liste des tags BIO correspondant aux tokens originaux\n",
        "\n",
        "        Returns:\n",
        "            Dictionnaire contenant les tokens BERT et les tags BIO alignés\n",
        "        \"\"\"\n",
        "        tokenized_inputs = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "            return_offsets_mapping=True,\n",
        "            return_special_tokens_mask=True,\n",
        "        )\n",
        "\n",
        "        # Créer une liste de tags BIO alignés avec les tokens BERT\n",
        "        aligned_labels = []\n",
        "\n",
        "        # Obtenir les positions des tokens originaux dans le texte\n",
        "        token_positions = []\n",
        "        current_pos = 0\n",
        "        for token in tokens:\n",
        "            start = text.find(token, current_pos)\n",
        "            if start == -1:  # Si le token n'est pas trouvé, essayer avec une recherche moins stricte\n",
        "                for i in range(current_pos, len(text)):\n",
        "                    if text[i:i+len(token)].lower() == token.lower():\n",
        "                        start = i\n",
        "                        break\n",
        "\n",
        "            if start != -1:\n",
        "                end = start + len(token)\n",
        "                token_positions.append((start, end))\n",
        "                current_pos = end\n",
        "            else:\n",
        "                # Si le token n'est toujours pas trouvé, utiliser la position actuelle\n",
        "                token_positions.append((current_pos, current_pos + len(token)))\n",
        "                current_pos += len(token)\n",
        "\n",
        "        # Aligner les tags BIO avec les tokens BERT\n",
        "        offset_mapping = tokenized_inputs.pop(\"offset_mapping\")[0].numpy()\n",
        "        special_tokens_mask = tokenized_inputs.pop(\"special_tokens_mask\")[0].numpy()\n",
        "\n",
        "        for i, (offset_start, offset_end) in enumerate(offset_mapping):\n",
        "            # Ignorer les tokens spéciaux ([CLS], [SEP], etc.)\n",
        "            if special_tokens_mask[i] == 1:\n",
        "                aligned_labels.append(\"O\")\n",
        "                continue\n",
        "\n",
        "            # Trouver le token original qui correspond à ce token BERT\n",
        "            token_idx = None\n",
        "            for j, (token_start, token_end) in enumerate(token_positions):\n",
        "                if offset_start >= token_start and offset_end <= token_end:\n",
        "                    token_idx = j\n",
        "                    break\n",
        "\n",
        "            # Si un token original est trouvé, utiliser son tag BIO\n",
        "            if token_idx is not None:\n",
        "                # Pour les tokens BERT qui sont des sous-mots (commençant par ##),\n",
        "                # utiliser \"I-\" au lieu de \"B-\" s'ils ne sont pas le premier sous-mot\n",
        "                current_tag = bio_tags[token_idx]\n",
        "\n",
        "                # Si ce n'est pas le premier token BERT pour ce token original\n",
        "                # et que le tag commence par \"B-\", le remplacer par \"I-\"\n",
        "                if i > 0 and offset_mapping[i-1][1] > 0 and token_idx == self._find_token_idx(offset_mapping[i-1], token_positions):\n",
        "                    if current_tag.startswith(\"B-\"):\n",
        "                        current_tag = \"I-\" + current_tag[2:]\n",
        "\n",
        "                aligned_labels.append(current_tag)\n",
        "            else:\n",
        "                # Si aucun token original ne correspond, utiliser \"O\"\n",
        "                aligned_labels.append(\"O\")\n",
        "\n",
        "        # Tronquer ou remplir la liste des labels pour qu'elle ait la même longueur que les tokens BERT\n",
        "        if len(aligned_labels) < self.max_length:\n",
        "            aligned_labels.extend([\"O\"] * (self.max_length - len(aligned_labels)))\n",
        "        else:\n",
        "            aligned_labels = aligned_labels[:self.max_length]\n",
        "\n",
        "        # Manually create token_type_ids as a tensor of zeros\n",
        "        token_type_ids = torch.zeros_like(tokenized_inputs[\"input_ids\"][0])\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": tokenized_inputs[\"input_ids\"][0],\n",
        "            \"attention_mask\": tokenized_inputs[\"attention_mask\"][0],\n",
        "            \"token_type_ids\": token_type_ids,  # Use the created token_type_ids\n",
        "            \"labels\": aligned_labels\n",
        "        }\n",
        "\n",
        "    def _find_token_idx(self, offset: Tuple[int, int], token_positions: List[Tuple[int, int]]) -> Optional[int]:\n",
        "        \"\"\"\n",
        "        Trouve l'indice du token original qui correspond à un offset donné.\n",
        "\n",
        "        Args:\n",
        "            offset: Tuple (start, end) représentant l'offset du token BERT\n",
        "            token_positions: Liste de tuples (start, end) représentant les positions des tokens originaux\n",
        "\n",
        "        Returns:\n",
        "            Indice du token original ou None si aucun ne correspond\n",
        "        \"\"\"\n",
        "        offset_start, offset_end = offset\n",
        "\n",
        "        for i, (token_start, token_end) in enumerate(token_positions):\n",
        "            if offset_start >= token_start and offset_end <= token_end:\n",
        "                return i\n",
        "\n",
        "        return None"
      ],
      "metadata": {
        "id": "UBjG8WhMS7jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchcrf\n",
        "!pip install git+https://github.com/kmkurn/pytorch-crf.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-0Zl7TCRdZQ",
        "outputId": "56275c29-7093-46cd-86fd-8cfcbaaadb21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: TorchCRF 1.1.0\n",
            "Uninstalling TorchCRF-1.1.0:\n",
            "  Successfully uninstalled TorchCRF-1.1.0\n",
            "Collecting git+https://github.com/kmkurn/pytorch-crf.git\n",
            "  Cloning https://github.com/kmkurn/pytorch-crf.git to /tmp/pip-req-build-yzojvzcu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/kmkurn/pytorch-crf.git /tmp/pip-req-build-yzojvzcu\n",
            "  Resolved https://github.com/kmkurn/pytorch-crf.git to commit 623e3402d00a2728e99d6e8486010d67c754267b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytorch-crf\n",
            "  Building wheel for pytorch-crf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-crf: filename=pytorch_crf-0.7.2-py3-none-any.whl size=6410 sha256=085178c1f147e8958dfb2f9063e3b9333678cdb4e4a2c56e5b36c4597ff4e2cb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pol31imo/wheels/fd/83/cc/f11543939f8911b8dcff86e2bd54423e21f779d0938958cc7f\n",
            "Successfully built pytorch-crf\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr9UOU6qPepT"
      },
      "source": [
        "### 2.3 Module de modélisation BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAF8yUofPepT"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import BertModel, BertPreTrainedModel, BertConfig\n",
        "from torchcrf import CRF\n",
        "from typing import Union\n",
        "\n",
        "class BERTForEventRecognition(BertPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Modèle BERT pour la reconnaissance d'événements basé sur une architecture de type NER.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_labels: int):\n",
        "        \"\"\"\n",
        "        Initialise le modèle BERT pour la reconnaissance d'événements.\n",
        "\n",
        "        Args:\n",
        "            config: Configuration du modèle BERT\n",
        "            num_labels: Nombre de labels (classes) pour la classification\n",
        "        \"\"\"\n",
        "        super().__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        # Modèle BERT de base\n",
        "        self.bert = BertModel(config)\n",
        "\n",
        "        # Dropout pour la régularisation\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # Couche de classification\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "        # Initialisation des poids\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
        "               position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
        "        \"\"\"\n",
        "        Passe avant du modèle.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Indices des tokens d'entrée\n",
        "            attention_mask: Masque d'attention\n",
        "            token_type_ids: Indices des types de tokens\n",
        "            position_ids: Indices de position\n",
        "            head_mask: Masque pour les têtes d'attention\n",
        "            inputs_embeds: Embeddings d'entrée\n",
        "            labels: Labels pour le calcul de la perte\n",
        "\n",
        "        Returns:\n",
        "            Tuple contenant la perte et les logits\n",
        "        \"\"\"\n",
        "        # Obtenir les embeddings de BERT\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        "\n",
        "        # Extraire les embeddings de la dernière couche cachée\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        # Appliquer le dropout\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        # Calculer les logits\n",
        "        logits = self.classifier(sequence_output)\n",
        "\n",
        "        # Calculer la perte si les labels sont fournis\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "\n",
        "            # Masquer les positions de padding\n",
        "            active_loss = attention_mask.view(-1) == 1\n",
        "            active_logits = logits.view(-1, self.num_labels)\n",
        "            active_labels = torch.where(\n",
        "                active_loss,\n",
        "                labels.view(-1),\n",
        "                torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
        "            )\n",
        "\n",
        "            loss = loss_fct(active_logits, active_labels)\n",
        "\n",
        "        return (loss, logits) if loss is not None else logits\n",
        "\n",
        "\n",
        "class BERTCRFForEventRecognition(BertPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Modèle BERT avec CRF pour la reconnaissance d'événements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_labels: int):\n",
        "        \"\"\"\n",
        "        Initialise le modèle BERT avec CRF pour la reconnaissance d'événements.\n",
        "\n",
        "        Args:\n",
        "            config: Configuration du modèle BERT\n",
        "            num_labels: Nombre de labels (classes) pour la classification\n",
        "        \"\"\"\n",
        "        super().__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        # Modèle BERT de base\n",
        "        self.bert = BertModel(config)\n",
        "\n",
        "        # Dropout pour la régularisation\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # Couche de classification\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "        # Couche CRF\n",
        "        self.crf = CRF(num_labels, batch_first=True)\n",
        "\n",
        "        # Initialisation des poids\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
        "               position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n",
        "        \"\"\"\n",
        "        Passe avant du modèle.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Indices des tokens d'entrée\n",
        "            attention_mask: Masque d'attention\n",
        "            token_type_ids: Indices des types de tokens\n",
        "            position_ids: Indices de position\n",
        "            head_mask: Masque pour les têtes d'attention\n",
        "            inputs_embeds: Embeddings d'entrée\n",
        "            labels: Labels pour le calcul de la perte\n",
        "\n",
        "        Returns:\n",
        "            Tuple contenant la perte et les logits\n",
        "        \"\"\"\n",
        "        # Obtenir les embeddings de BERT\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        "\n",
        "        # Extraire les embeddings de la dernière couche cachée\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        # Appliquer le dropout\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "        # Calculer les logits\n",
        "        emissions = self.classifier(sequence_output)\n",
        "\n",
        "        # Calculer la perte si les labels sont fournis\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # Masquer les positions de padding pour le CRF\n",
        "            mask = attention_mask.type(torch.bool)\n",
        "\n",
        "            # Calculer la log-vraisemblance négative\n",
        "            loss = -self.crf(emissions, labels, mask=mask, reduction='mean')\n",
        "\n",
        "        return (loss, emissions) if loss is not None else emissions\n",
        "\n",
        "    def decode(self, emissions, mask=None):\n",
        "        \"\"\"\n",
        "        Décode les émissions pour obtenir les meilleurs chemins (séquences de labels).\n",
        "\n",
        "        Args:\n",
        "            emissions: Émissions du modèle\n",
        "            mask: Masque pour les positions valides\n",
        "\n",
        "        Returns:\n",
        "            Liste des meilleurs chemins\n",
        "        \"\"\"\n",
        "        return self.crf.decode(emissions, mask=mask)\n",
        "\n",
        "\n",
        "class BERTModelSelector:\n",
        "    \"\"\"\n",
        "    Classe pour sélectionner et configurer un modèle BERT adapté à la tâche de reconnaissance d'événements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_labels: int, use_crf: bool = True):\n",
        "        \"\"\"\n",
        "        Initialise le sélecteur de modèle.\n",
        "\n",
        "        Args:\n",
        "            num_labels: Nombre de labels (classes) pour la classification\n",
        "            use_crf: Utiliser une couche CRF pour améliorer les prédictions\n",
        "        \"\"\"\n",
        "        self.num_labels = num_labels\n",
        "        self.use_crf = use_crf\n",
        "\n",
        "    def select_model(self, model_name: str = \"camembert-base\") -> Union[BERTForEventRecognition, BERTCRFForEventRecognition]:\n",
        "        \"\"\"\n",
        "        Sélectionne et configure un modèle BERT adapté à la tâche de reconnaissance d'événements.\n",
        "\n",
        "        Args:\n",
        "            model_name: Nom du modèle BERT à utiliser\n",
        "\n",
        "        Returns:\n",
        "            Modèle BERT configuré pour la reconnaissance d'événements\n",
        "        \"\"\"\n",
        "        # Charger la configuration du modèle\n",
        "        config = BertConfig.from_pretrained(model_name)\n",
        "\n",
        "        # Créer le modèle\n",
        "        if self.use_crf:\n",
        "            model = BERTCRFForEventRecognition.from_pretrained(\n",
        "                model_name,\n",
        "                config=config,\n",
        "                num_labels=self.num_labels\n",
        "            )\n",
        "        else:\n",
        "            model = BERTForEventRecognition.from_pretrained(\n",
        "                model_name,\n",
        "                config=config,\n",
        "                num_labels=self.num_labels\n",
        "            )\n",
        "\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def get_recommended_models() -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Retourne une liste de modèles BERT recommandés pour la tâche de reconnaissance d'événements.\n",
        "\n",
        "        Returns:\n",
        "            Liste de dictionnaires contenant les informations sur les modèles recommandés\n",
        "        \"\"\"\n",
        "        return [\n",
        "            {\n",
        "                \"name\": \"camembert-base\",\n",
        "                \"description\": \"Modèle BERT français, pré-entraîné sur un large corpus français\",\n",
        "                \"advantages\": \"Excellente performance sur les textes français, meilleure compréhension des nuances linguistiques\",\n",
        "                \"disadvantages\": \"Limité au français, peut être moins adapté si le corpus contient d'autres langues\"\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"bert-base-multilingual-cased\",\n",
        "                \"description\": \"Modèle BERT multilingue (cased) pré-entraîné sur 104 langues, dont le français\",\n",
        "                \"advantages\": \"Bonne performance sur les langues non-anglaises, adapté aux textes français\",\n",
        "                \"disadvantages\": \"Moins performant que les modèles spécifiques au français sur certaines tâches\"\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"flaubert/flaubert_base_cased\",\n",
        "                \"description\": \"Modèle BERT français alternatif, pré-entraîné sur un corpus français diversifié\",\n",
        "                \"advantages\": \"Bonne performance sur les textes français, architecture optimisée\",\n",
        "                \"disadvantages\": \"Limité au français, peut nécessiter plus de ressources computationnelles\"\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"xlm-roberta-base\",\n",
        "                \"description\": \"Modèle RoBERTa multilingue, pré-entraîné sur 100 langues avec une architecture améliorée\",\n",
        "                \"advantages\": \"Performances supérieures à BERT multilingue sur de nombreuses tâches, robuste aux variations linguistiques\",\n",
        "                \"disadvantages\": \"Plus lourd en termes de ressources computationnelles\"\n",
        "            }\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdBWbODAPepV"
      },
      "source": [
        "### 2.4 Module de fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RM8TXUIPepV"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "import time\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import logging\n",
        "\n",
        "# Configuration du logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Classe pour implémenter l'early stopping pendant l'entraînement.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, patience: int = 3, min_delta: float = 0.0, restore_best_weights: bool = True):\n",
        "        \"\"\"\n",
        "        Initialise l'early stopping.\n",
        "\n",
        "        Args:\n",
        "            patience: Nombre d'époques à attendre après la dernière amélioration\n",
        "            min_delta: Amélioration minimale pour être considérée comme une amélioration\n",
        "            restore_best_weights: Restaurer les meilleurs poids à la fin\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_score = None\n",
        "        self.best_weights = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, score: float, model: torch.nn.Module) -> bool:\n",
        "        \"\"\"\n",
        "        Vérifie si l'entraînement doit être arrêté.\n",
        "\n",
        "        Args:\n",
        "            score: Score actuel (plus élevé est meilleur)\n",
        "            model: Modèle actuel\n",
        "\n",
        "        Returns:\n",
        "            True si l'entraînement doit être arrêté, False sinon\n",
        "        \"\"\"\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.best_weights = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "        elif score < self.best_score + self.min_delta:\n",
        "            self.counter += 1\n",
        "            logger.info(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                if self.restore_best_weights:\n",
        "                    model.load_state_dict(self.best_weights)\n",
        "                return True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.best_weights = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            self.counter = 0\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "class MetricsTracker:\n",
        "    \"\"\"\n",
        "    Classe pour suivre les métriques pendant l'entraînement.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialise le tracker de métriques.\n",
        "        \"\"\"\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.val_f1_scores = []\n",
        "        self.val_precision_scores = []\n",
        "        self.val_recall_scores = []\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def update(self, train_loss: float, val_loss: float, val_f1: float, val_precision: float, val_recall: float, lr: float):\n",
        "        \"\"\"\n",
        "        Met à jour les métriques.\n",
        "\n",
        "        Args:\n",
        "            train_loss: Perte d'entraînement\n",
        "            val_loss: Perte de validation\n",
        "            val_f1: F1-score de validation\n",
        "            val_precision: Précision de validation\n",
        "            val_recall: Rappel de validation\n",
        "            lr: Taux d'apprentissage actuel\n",
        "        \"\"\"\n",
        "        self.train_losses.append(train_loss)\n",
        "        self.val_losses.append(val_loss)\n",
        "        self.val_f1_scores.append(val_f1)\n",
        "        self.val_precision_scores.append(val_precision)\n",
        "        self.val_recall_scores.append(val_recall)\n",
        "        self.learning_rates.append(lr)\n",
        "\n",
        "    def plot_metrics(self, save_path: str = \"training_metrics.png\"):\n",
        "        \"\"\"\n",
        "        Trace les métriques d'entraînement.\n",
        "\n",
        "        Args:\n",
        "            save_path: Chemin pour sauvegarder le graphique\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        # Tracer les pertes\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.plot(self.train_losses, label=\"Train Loss\")\n",
        "        plt.plot(self.val_losses, label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training and Validation Loss\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Tracer les F1-scores\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(self.val_f1_scores, label=\"F1-Score\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"F1-Score\")\n",
        "        plt.title(\"Validation F1-Score\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Tracer la précision et le rappel\n",
        "        plt.subplot(2, 2, 3)\n",
        "        plt.plot(self.val_precision_scores, label=\"Precision\")\n",
        "        plt.plot(self.val_recall_scores, label=\"Recall\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Score\")\n",
        "        plt.title(\"Validation Precision and Recall\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Tracer le taux d'apprentissage\n",
        "        plt.subplot(2, 2, 4)\n",
        "        plt.plot(self.learning_rates)\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Learning Rate\")\n",
        "        plt.title(\"Learning Rate\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "\n",
        "    def save_metrics(self, save_path: str = \"training_metrics.json\"):\n",
        "        \"\"\"\n",
        "        Sauvegarde les métriques dans un fichier JSON.\n",
        "\n",
        "        Args:\n",
        "            save_path: Chemin pour sauvegarder les métriques\n",
        "        \"\"\"\n",
        "        metrics = {\n",
        "            \"train_losses\": self.train_losses,\n",
        "            \"val_losses\": self.val_losses,\n",
        "            \"val_f1_scores\": self.val_f1_scores,\n",
        "            \"val_precision_scores\": self.val_precision_scores,\n",
        "            \"val_recall_scores\": self.val_recall_scores,\n",
        "            \"learning_rates\": self.learning_rates\n",
        "        }\n",
        "\n",
        "        with open(save_path, \"w\") as f:\n",
        "            json.dump(metrics, f, indent=4)\n",
        "\n",
        "\n",
        "class BERTFineTuner:\n",
        "    \"\"\"\n",
        "    Classe pour fine-tuner un modèle BERT pour la reconnaissance d'événements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: torch.nn.Module, id_to_label: Dict[int, str], device: str = None):\n",
        "        \"\"\"\n",
        "        Initialise le fine-tuner.\n",
        "\n",
        "        Args:\n",
        "            model: Modèle BERT à fine-tuner\n",
        "            id_to_label: Dictionnaire mappant les indices numériques aux tags BIO\n",
        "            device: Appareil sur lequel exécuter l'entraînement (cpu ou cuda)\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.id_to_label = id_to_label\n",
        "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        logger.info(f\"Using device: {self.device}\")\n",
        "\n",
        "    def train(self, train_dataloader: torch.utils.data.DataLoader, val_dataloader: torch.utils.data.DataLoader,\n",
        "             epochs: int = 10, learning_rate: float = 2e-5, weight_decay: float = 0.01,\n",
        "             warmup_steps: int = 0, max_grad_norm: float = 1.0, output_dir: str = \"model_output\"):\n",
        "        \"\"\"\n",
        "        Fine-tune le modèle BERT.\n",
        "\n",
        "        Args:\n",
        "            train_dataloader: DataLoader pour les données d'entraînement\n",
        "            val_dataloader: DataLoader pour les données de validation\n",
        "            epochs: Nombre d'époques d'entraînement\n",
        "            learning_rate: Taux d'apprentissage initial\n",
        "            weight_decay: Décroissance des poids pour la régularisation\n",
        "            warmup_steps: Nombre d'étapes de warmup pour le scheduler\n",
        "            max_grad_norm: Norme maximale du gradient pour le clipping\n",
        "            output_dir: Répertoire pour sauvegarder le modèle\n",
        "\n",
        "        Returns:\n",
        "            Métriques d'entraînement\n",
        "        \"\"\"\n",
        "        # Créer le répertoire de sortie s'il n'existe pas\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Initialiser l'optimiseur\n",
        "        optimizer = AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "        # Calculer le nombre total d'étapes d'entraînement\n",
        "        total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "        # Initialiser le scheduler\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=warmup_steps,\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        # Initialiser le scheduler de réduction du taux d'apprentissage\n",
        "        lr_scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "        # Initialiser l'early stopping\n",
        "        early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "        # Initialiser le tracker de métriques\n",
        "        metrics_tracker = MetricsTracker()\n",
        "\n",
        "        # Boucle d'entraînement\n",
        "        logger.info(\"Starting training...\")\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Entraînement\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "            train_steps = 0\n",
        "\n",
        "            progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
        "            for batch in progress_bar:\n",
        "                # Déplacer les tenseurs sur le device\n",
        "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(\n",
        "                    input_ids=batch[\"input_ids\"],\n",
        "                    attention_mask=batch[\"attention_mask\"],\n",
        "                    token_type_ids=batch[\"token_type_ids\"],\n",
        "                    labels=batch[\"labels\"]\n",
        "                )\n",
        "\n",
        "                loss = outputs[0]\n",
        "\n",
        "                # Backward pass\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "                # Clipping du gradient\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_grad_norm)\n",
        "\n",
        "                # Mise à jour des poids\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # Mise à jour de la perte\n",
        "                train_loss += loss.item()\n",
        "                train_steps += 1\n",
        "\n",
        "                # Mise à jour de la barre de progression\n",
        "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "            # Calculer la perte moyenne d'entraînement\n",
        "            avg_train_loss = train_loss / train_steps\n",
        "\n",
        "            # Validation\n",
        "            self.model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_steps = 0\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "\n",
        "            progress_bar = tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\")\n",
        "            with torch.no_grad():\n",
        "                for batch in progress_bar:\n",
        "                    # Déplacer les tenseurs sur le device\n",
        "                    batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "\n",
        "                    # Forward pass\n",
        "                    outputs = self.model(\n",
        "                        input_ids=batch[\"input_ids\"],\n",
        "                        attention_mask=batch[\"attention_mask\"],\n",
        "                        token_type_ids=batch[\"token_type_ids\"],\n",
        "                        labels=batch[\"labels\"]\n",
        "                    )\n",
        "\n",
        "                    loss, logits = outputs[:2]\n",
        "\n",
        "                    # Mise à jour de la perte\n",
        "                    val_loss += loss.item()\n",
        "                    val_steps += 1\n",
        "\n",
        "                    # Obtenir les prédictions\n",
        "                    if hasattr(self.model, 'decode'):\n",
        "                        # Pour les modèles avec CRF\n",
        "                        preds = self.model.decode(logits, mask=batch[\"attention_mask\"].bool())\n",
        "                        preds = [p for sublist in preds for p in sublist]  # Aplatir la liste\n",
        "                    else:\n",
        "                        # Pour les modèles sans CRF\n",
        "                        preds = torch.argmax(logits, dim=2).flatten().cpu().numpy()\n",
        "\n",
        "                    # Obtenir les labels réels (ignorer les tokens spéciaux et le padding)\n",
        "                    labels = batch[\"labels\"].flatten().cpu().numpy()\n",
        "                    mask = batch[\"attention_mask\"].flatten().cpu().numpy()\n",
        "\n",
        "                    # Filtrer les tokens spéciaux et le padding\n",
        "                    valid_indices = np.where(mask == 1)[0]\n",
        "                    filtered_preds = [preds[i] for i in valid_indices] if hasattr(self.model, 'decode') else preds[valid_indices]\n",
        "                    filtered_labels = labels[valid_indices]\n",
        "\n",
        "                    all_preds.extend(filtered_preds)\n",
        "                    all_labels.extend(filtered_labels)\n",
        "\n",
        "                    # Mise à jour de la barre de progression\n",
        "                    progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "            # Calculer la perte moyenne de validation\n",
        "            avg_val_loss = val_loss / val_steps\n",
        "\n",
        "            # Calculer les métriques\n",
        "            val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "            val_precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "            val_recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "            # Mettre à jour le scheduler de réduction du taux d'apprentissage\n",
        "            lr_scheduler.step(val_f1)\n",
        "\n",
        "            # Obtenir le taux d'apprentissage actuel\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # Mettre à jour le tracker de métriques\n",
        "            metrics_tracker.update(avg_train_loss, avg_val_loss, val_f1, val_precision, val_recall, current_lr)\n",
        "\n",
        "            # Afficher les métriques\n",
        "            logger.info(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "            logger.info(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
        "            logger.info(f\"  Val Loss: {avg_val_loss:.4f}\")\n",
        "            logger.info(f\"  Val F1: {val_f1:.4f}\")\n",
        "            logger.info(f\"  Val Precision: {val_precision:.4f}\")\n",
        "            logger.info(f\"  Val Recall: {val_recall:.4f}\")\n",
        "            logger.info(f\"  Learning Rate: {current_lr:.8f}\")\n",
        "\n",
        "            # Sauvegarder le modèle\n",
        "            model_path = os.path.join(output_dir, f\"model_epoch_{epoch+1}\")\n",
        "            os.makedirs(model_path, exist_ok=True)\n",
        "            self.model.save_pretrained(model_path)\n",
        "            logger.info(f\"Model saved to {model_path}\")\n",
        "\n",
        "            # Vérifier l'early stopping\n",
        "            if early_stopping(val_f1, self.model):\n",
        "                logger.info(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "        # Tracer et sauvegarder les métriques\n",
        "        metrics_tracker.plot_metrics(os.path.join(output_dir, \"training_metrics.png\"))\n",
        "        metrics_tracker.save_metrics(os.path.join(output_dir, \"training_metrics.json\"))\n",
        "\n",
        "        # Sauvegarder le modèle final\n",
        "        final_model_path = os.path.join(output_dir, \"final_model\")\n",
        "        os.makedirs(final_model_path, exist_ok=True)\n",
        "        self.model.save_pretrained(final_model_path)\n",
        "        logger.info(f\"Final model saved to {final_model_path}\")\n",
        "\n",
        "        return metrics_tracker\n",
        "\n",
        "    def evaluate(self, test_dataloader: torch.utils.data.DataLoader, output_dir: str = \"evaluation_output\"):\n",
        "        \"\"\"\n",
        "        Évalue le modèle sur un ensemble de test.\n",
        "\n",
        "        Args:\n",
        "            test_dataloader: DataLoader pour les données de test\n",
        "            output_dir: Répertoire pour sauvegarder les résultats d'évaluation\n",
        "\n",
        "        Returns:\n",
        "            Métriques d'évaluation\n",
        "        \"\"\"\n",
        "        # Créer le répertoire de sortie s'il n'existe pas\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Évaluation\n",
        "        self.model.eval()\n",
        "        test_loss = 0.0\n",
        "        test_steps = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        progress_bar = tqdm(test_dataloader, desc=\"Evaluation\")\n",
        "        with torch.no_grad():\n",
        "            for batch in progress_bar:\n",
        "                # Déplacer les tenseurs sur le device\n",
        "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(\n",
        "                    input_ids=batch[\"input_ids\"],\n",
        "                    attention_mask=batch[\"attention_mask\"],\n",
        "                    token_type_ids=batch[\"token_type_ids\"],\n",
        "                    labels=batch[\"labels\"]\n",
        "                )\n",
        "\n",
        "                loss, logits = outputs[:2]\n",
        "\n",
        "                # Mise à jour de la perte\n",
        "                test_loss += loss.item()\n",
        "                test_steps += 1\n",
        "\n",
        "                # Obtenir les prédictions\n",
        "                if hasattr(self.model, 'decode'):\n",
        "                    # Pour les modèles avec CRF\n",
        "                    preds = self.model.decode(logits, mask=batch[\"attention_mask\"].bool())\n",
        "                    preds = [p for sublist in preds for p in sublist]  # Aplatir la liste\n",
        "                else:\n",
        "                    # Pour les modèles sans CRF\n",
        "                    preds = torch.argmax(logits, dim=2).flatten().cpu().numpy()\n",
        "\n",
        "                # Obtenir les labels réels (ignorer les tokens spéciaux et le padding)\n",
        "                labels = batch[\"labels\"].flatten().cpu().numpy()\n",
        "                mask = batch[\"attention_mask\"].flatten().cpu().numpy()\n",
        "\n",
        "                # Filtrer les tokens spéciaux et le padding\n",
        "                valid_indices = np.where(mask == 1)[0]\n",
        "                filtered_preds = [preds[0][i] for i in valid_indices] if hasattr(self.model, 'decode') else preds[valid_indices]\n",
        "                filtered_labels = labels[valid_indices]\n",
        "\n",
        "                all_preds.extend(filtered_preds)\n",
        "                all_labels.extend(filtered_labels)\n",
        "\n",
        "                # Mise à jour de la barre de progression\n",
        "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "        # Calculer la perte moyenne de test\n",
        "        avg_test_loss = test_loss / test_steps\n",
        "\n",
        "        # Convertir les indices en labels\n",
        "        pred_labels = [self.id_to_label[p] for p in all_preds]\n",
        "        true_labels = [self.id_to_label[l] for l in all_labels]\n",
        "\n",
        "        # Calculer les métriques\n",
        "        report = classification_report(all_labels, all_preds, target_names=list(self.id_to_label.values()), output_dict=True)\n",
        "\n",
        "        # Sauvegarder le rapport de classification\n",
        "        with open(os.path.join(output_dir, \"classification_report.json\"), \"w\") as f:\n",
        "            json.dump(report, f, indent=4)\n",
        "\n",
        "        # Afficher les métriques\n",
        "        logger.info(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "        logger.info(f\"Test F1 (weighted): {report['weighted avg']['f1-score']:.4f}\")\n",
        "        logger.info(f\"Test Precision (weighted): {report['weighted avg']['precision']:.4f}\")\n",
        "        logger.info(f\"Test Recall (weighted): {report['weighted avg']['recall']:.4f}\")\n",
        "\n",
        "        return {\n",
        "            \"loss\": avg_test_loss,\n",
        "            \"f1\": report['weighted avg']['f1-score'],\n",
        "            \"precision\": report['weighted avg']['precision'],\n",
        "            \"recall\": report['weighted avg']['recall'],\n",
        "            \"report\": report\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnmPgAnOPepX"
      },
      "source": [
        "## 3. Pipeline complet de reconnaissance d'événements\n",
        "\n",
        "### 3.1 Chargement et prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QUDbPVBPepX",
        "outputId": "9c3a681d-07ab-4068-a6f1-fc371ce52ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement des données depuis /content/drive/MyDrive/annotation...\n",
            "Nombre d'exemples chargés: 1441\n",
            "Nombre d'exemples d'entraînement: 1008\n",
            "Nombre d'exemples de validation: 216\n",
            "Nombre d'exemples de test: 217\n"
          ]
        }
      ],
      "source": [
        "# Créer le builder de dataset\n",
        "builder = DatasetBuilder(EVENT_TYPES)\n",
        "\n",
        "# Construire le dataset à partir des fichiers TSV\n",
        "print(f\"Chargement des données depuis {ANNOTATIONS_DIR}...\")\n",
        "dataset = builder.build_from_directory(ANNOTATIONS_DIR, pattern=\"*/MBY3.tsv\")\n",
        "print(f\"Nombre d'exemples chargés: {len(dataset)}\")\n",
        "\n",
        "# Diviser le dataset en ensembles d'entraînement, de validation et de test\n",
        "train_data, val_data, test_data = builder.split_dataset(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
        "print(f\"Nombre d'exemples d'entraînement: {len(train_data)}\")\n",
        "print(f\"Nombre d'exemples de validation: {len(val_data)}\")\n",
        "print(f\"Nombre d'exemples de test: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBIsRodhPepY"
      },
      "source": [
        "### 3.2 Tokenisation et encodage des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1rXVaZSPepY",
        "outputId": "85d96e9b-b6bb-4dca-cc7e-a412b714acc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenisation et encodage des données avec camembert-base...\n",
            "Nombre de labels: 11\n",
            "Labels: {'O': 0, 'B-conflit': 1, 'I-conflit': 2, 'B-décision gouvernementale': 3, 'I-décision gouvernementale': 4, 'B-décès': 5, 'I-décès': 6, 'B-avancée technologique': 7, 'I-avancée technologique': 8, 'B-événement culturel': 9, 'I-événement culturel': 10}\n"
          ]
        }
      ],
      "source": [
        "# Définir le modèle BERT à utiliser\n",
        "MODEL_NAME = \"camembert-base\"  # Vous pouvez changer pour \"bert-base-multilingual-cased\", \"flaubert/flaubert_base_cased\", etc.\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Créer le processeur de données\n",
        "processor = BERTDataProcessor(MODEL_NAME, MAX_LENGTH, EVENT_TYPES)\n",
        "\n",
        "# Créer les datasets PyTorch\n",
        "print(f\"Tokenisation et encodage des données avec {MODEL_NAME}...\")\n",
        "train_dataset, val_dataset, test_dataset = processor.process_bio_data(dataset)\n",
        "\n",
        "# Créer les dataloaders\n",
        "train_dataloader, val_dataloader, test_dataloader = processor.create_data_loaders(\n",
        "    train_dataset, val_dataset, test_dataset, BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Obtenir le mapping des labels\n",
        "label_map = processor.get_label_map()\n",
        "id_to_label = processor.get_id_to_label()\n",
        "\n",
        "print(f\"Nombre de labels: {len(label_map)}\")\n",
        "print(f\"Labels: {label_map}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dRCpduPPepZ"
      },
      "source": [
        "### 3.3 Configuration et entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822,
          "referenced_widgets": [
            "77e0bf1becd34f9ab5b56267285c58e5",
            "6aa4e1739f684170805be7c3c1892c3c",
            "4f5d7f1e600144e48bf55556ee5b67fd",
            "5a2c7d9134cf4258861c79b7e2728384",
            "0607bc71a42e45d3be2dfbafd47a5d41",
            "83926413895848359354db0b4670b383",
            "5c6ac315dc6a4f7fbc9b22ae97faf7ff",
            "84430fa93be7492f93d162011a7923a8",
            "f711f4da4b82449daece525a103fe0e5",
            "dfcb0f038c1241bb93438f9df5922427",
            "0842395f60734496a5c2e3786670160c",
            "5c5f5c29623f4739a27d1e21c629e5ab",
            "8e275b0daf964fb398f92432d7a39657",
            "8b3a3f70c6204fc3bfc2773ca0595a3c",
            "d17f2b29aaa8452195c51cbba3b518eb",
            "15e51adc208f4131a2217f7451941a39",
            "0d4c07dadfeb44e398a7ea52e24664d4",
            "179203cdd5e14339933b40038817fb28",
            "ad22b17a8ffe4cc6a28dd64302949be2",
            "7328027147f943f18fb354c97dd7653f",
            "302de9c0231e48c2b3ef8dd5428f52ba",
            "bbf1becae9b34f09b6b9df4bb9babb74"
          ]
        },
        "id": "GvD9c0EpPepZ",
        "outputId": "65088168-4dca-4ccb-b9ec-f38c008d139d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type camembert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèles BERT recommandés pour la reconnaissance d'événements:\n",
            "- camembert-base: Modèle BERT français, pré-entraîné sur un large corpus français\n",
            "  Avantages: Excellente performance sur les textes français, meilleure compréhension des nuances linguistiques\n",
            "  Inconvénients: Limité au français, peut être moins adapté si le corpus contient d'autres langues\n",
            "\n",
            "- bert-base-multilingual-cased: Modèle BERT multilingue (cased) pré-entraîné sur 104 langues, dont le français\n",
            "  Avantages: Bonne performance sur les langues non-anglaises, adapté aux textes français\n",
            "  Inconvénients: Moins performant que les modèles spécifiques au français sur certaines tâches\n",
            "\n",
            "- flaubert/flaubert_base_cased: Modèle BERT français alternatif, pré-entraîné sur un corpus français diversifié\n",
            "  Avantages: Bonne performance sur les textes français, architecture optimisée\n",
            "  Inconvénients: Limité au français, peut nécessiter plus de ressources computationnelles\n",
            "\n",
            "- xlm-roberta-base: Modèle RoBERTa multilingue, pré-entraîné sur 100 langues avec une architecture améliorée\n",
            "  Avantages: Performances supérieures à BERT multilingue sur de nombreuses tâches, robuste aux variations linguistiques\n",
            "  Inconvénients: Plus lourd en termes de ressources computationnelles\n",
            "\n",
            "Configuration du modèle camembert-base (CRF: True)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BERTCRFForEventRecognition were not initialized from the model checkpoint at camembert-base and are newly initialized: ['bert.embeddings.LayerNorm.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'crf.end_transitions', 'crf.start_transitions', 'crf.transitions']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Début de l'entraînement...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/10 [Train]:   0%|          | 0/63 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77e0bf1becd34f9ab5b56267285c58e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/10 [Val]:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c5f5c29623f4739a27d1e21c629e5ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-952ce16e58f0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Entraîner le modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Début de l'entraînement...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m metrics = fine_tuner.train(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-a936b06e1797>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, val_dataloader, epochs, learning_rate, weight_decay, warmup_steps, max_grad_norm, output_dir)\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0;31m# Filtrer les tokens spéciaux et le padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mvalid_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                     \u001b[0mfiltered_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decode'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m                     \u001b[0mfiltered_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-a936b06e1797>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0;31m# Filtrer les tokens spéciaux et le padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mvalid_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                     \u001b[0mfiltered_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decode'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m                     \u001b[0mfiltered_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Paramètres d'entraînement\n",
        "USE_CRF = True\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 3e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_STEPS = 500\n",
        "MAX_GRAD_NORM = 1.0\n",
        "\n",
        "# Créer le sélecteur de modèle\n",
        "selector = BERTModelSelector(len(label_map), USE_CRF)\n",
        "\n",
        "# Afficher les modèles recommandés\n",
        "print(\"Modèles BERT recommandés pour la reconnaissance d'événements:\")\n",
        "for model_info in selector.get_recommended_models():\n",
        "    print(f\"- {model_info['name']}: {model_info['description']}\")\n",
        "    print(f\"  Avantages: {model_info['advantages']}\")\n",
        "    print(f\"  Inconvénients: {model_info['disadvantages']}\")\n",
        "    print()\n",
        "\n",
        "# Sélectionner le modèle\n",
        "print(f\"Configuration du modèle {MODEL_NAME} (CRF: {USE_CRF})...\")\n",
        "model = selector.select_model(MODEL_NAME)\n",
        "\n",
        "# Créer le fine-tuner\n",
        "fine_tuner = BERTFineTuner(model, id_to_label)\n",
        "\n",
        "# Entraîner le modèle\n",
        "print(\"Début de l'entraînement...\")\n",
        "metrics = fine_tuner.train(\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    epochs=EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    warmup_steps=WARMUP_STEPS,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        "    output_dir=os.path.join(OUTPUT_DIR, \"model\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPNkY1vIPepa"
      },
      "source": [
        "### 3.4 Évaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeuNfCbdPepb"
      },
      "outputs": [],
      "source": [
        "# Évaluer le modèle sur l'ensemble de test\n",
        "print(\"Évaluation du modèle sur l'ensemble de test...\")\n",
        "eval_results = fine_tuner.evaluate(\n",
        "    test_dataloader,\n",
        "    output_dir=os.path.join(OUTPUT_DIR, \"evaluation\")\n",
        ")\n",
        "\n",
        "# Afficher les résultats\n",
        "print(f\"F1-score: {eval_results['f1']:.4f}\")\n",
        "print(f\"Précision: {eval_results['precision']:.4f}\")\n",
        "print(f\"Rappel: {eval_results['recall']:.4f}\")\n",
        "\n",
        "# Afficher le rapport de classification\n",
        "print(\"\\nRapport de classification:\")\n",
        "for label, metrics in eval_results['report'].items():\n",
        "    if isinstance(metrics, dict):\n",
        "        print(f\"{label}:\")\n",
        "        print(f\"  Précision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Rappel: {metrics['recall']:.4f}\")\n",
        "        print(f\"  F1-score: {metrics['f1-score']:.4f}\")\n",
        "        print(f\"  Support: {metrics['support']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5DN6sfUPepb"
      },
      "source": [
        "### 3.5 Utilisation du modèle pour la prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOhkebYXPepc"
      },
      "outputs": [],
      "source": [
        "def predict_events(text, model, tokenizer, id_to_label, device=None):\n",
        "    \"\"\"\n",
        "    Prédit les événements dans un texte.\n",
        "\n",
        "    Args:\n",
        "        text: Texte à analyser\n",
        "        model: Modèle BERT entraîné\n",
        "        tokenizer: Tokenizer BERT\n",
        "        id_to_label: Dictionnaire mappant les indices numériques aux tags BIO\n",
        "        device: Appareil sur lequel exécuter la prédiction (cpu ou cuda)\n",
        "\n",
        "    Returns:\n",
        "        Liste de tuples (token, tag)\n",
        "    \"\"\"\n",
        "    device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Tokeniser le texte\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        return_offsets_mapping=True,\n",
        "        return_special_tokens_mask=True\n",
        "    )\n",
        "\n",
        "    # Obtenir les offsets et le masque des tokens spéciaux\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")[0].numpy()\n",
        "    special_tokens_mask = inputs.pop(\"special_tokens_mask\")[0].numpy()\n",
        "\n",
        "    # Déplacer les tenseurs sur le device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Prédire les tags\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        if hasattr(model, 'decode'):\n",
        "            # Pour les modèles avec CRF\n",
        "            preds = model.decode(outputs, mask=inputs[\"attention_mask\"].bool())[0]\n",
        "        else:\n",
        "            # Pour les modèles sans CRF\n",
        "            preds = torch.argmax(outputs, dim=2)[0].cpu().numpy()\n",
        "\n",
        "    # Convertir les prédictions en tags\n",
        "    tags = [id_to_label[p] for p in preds]\n",
        "\n",
        "    # Obtenir les tokens\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].cpu().numpy())\n",
        "\n",
        "    # Filtrer les tokens spéciaux\n",
        "    result = []\n",
        "    for i, (token, tag) in enumerate(zip(tokens, tags)):\n",
        "        if special_tokens_mask[i] == 0:  # Ignorer les tokens spéciaux\n",
        "            result.append((token, tag))\n",
        "\n",
        "    return result\n",
        "\n",
        "# Exemple d'utilisation\n",
        "tokenizer = processor.tokenizer_wrapper.tokenizer\n",
        "\n",
        "# Texte d'exemple\n",
        "example_text = \"Le gouvernement français a annoncé hier une nouvelle décision concernant la politique énergétique du pays.\"\n",
        "\n",
        "# Prédire les événements\n",
        "predictions = predict_events(example_text, model, tokenizer, id_to_label)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(\"Prédictions:\")\n",
        "for token, tag in predictions:\n",
        "    print(f\"{token}: {tag}\")\n",
        "\n",
        "# Extraire les événements\n",
        "events = []\n",
        "current_event = None\n",
        "\n",
        "for i, (token, tag) in enumerate(predictions):\n",
        "    if tag.startswith(\"B-\"):\n",
        "        if current_event:\n",
        "            events.append(current_event)\n",
        "        event_type = tag[2:]\n",
        "        current_event = {\"type\": event_type, \"tokens\": [token]}\n",
        "    elif tag.startswith(\"I-\") and current_event and tag[2:] == current_event[\"type\"]:\n",
        "        current_event[\"tokens\"].append(token)\n",
        "    elif tag == \"O\":\n",
        "        if current_event:\n",
        "            events.append(current_event)\n",
        "            current_event = None\n",
        "\n",
        "if current_event:\n",
        "    events.append(current_event)\n",
        "\n",
        "# Afficher les événements extraits\n",
        "print(\"\\nÉvénements extraits:\")\n",
        "for event in events:\n",
        "    print(f\"Type: {event['type']}\")\n",
        "    print(f\"Texte: {''.join(event['tokens']).replace('##', '')}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUf5rNqePepd"
      },
      "source": [
        "### 3.6 Sauvegarde du modèle et du tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oLwyCD1Pepe"
      },
      "outputs": [],
      "source": [
        "# Sauvegarder le modèle et le tokenizer dans Google Drive\n",
        "SAVE_DIR = '/content/drive/MyDrive/event_recognition_model'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Sauvegarder le modèle\n",
        "model.save_pretrained(SAVE_DIR)\n",
        "\n",
        "# Sauvegarder le tokenizer\n",
        "tokenizer.save_pretrained(SAVE_DIR)\n",
        "\n",
        "# Sauvegarder le mapping des labels\n",
        "with open(os.path.join(SAVE_DIR, 'label_map.json'), 'w') as f:\n",
        "    json.dump({\"label_map\": label_map, \"id_to_label\": id_to_label}, f, indent=4)\n",
        "\n",
        "print(f\"Modèle, tokenizer et mapping des labels sauvegardés dans {SAVE_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DwuxoamPepf"
      },
      "source": [
        "## 4. Conclusion\n",
        "\n",
        "Félicitations ! Vous avez maintenant un pipeline complet pour la reconnaissance automatique d'événements dans des textes. Ce pipeline comprend :\n",
        "\n",
        "1. Le prétraitement des données annotées au format WebAnno TSV 3.3\n",
        "2. La tokenisation et l'encodage des textes pour BERT\n",
        "3. La configuration et l'entraînement d'un modèle BERT (avec ou sans CRF)\n",
        "4. L'évaluation des performances du modèle\n",
        "5. L'utilisation du modèle pour la prédiction sur de nouveaux textes\n",
        "\n",
        "Vous pouvez maintenant utiliser ce modèle pour détecter automatiquement les événements dans vos textes !"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77e0bf1becd34f9ab5b56267285c58e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6aa4e1739f684170805be7c3c1892c3c",
              "IPY_MODEL_4f5d7f1e600144e48bf55556ee5b67fd",
              "IPY_MODEL_5a2c7d9134cf4258861c79b7e2728384"
            ],
            "layout": "IPY_MODEL_0607bc71a42e45d3be2dfbafd47a5d41"
          }
        },
        "6aa4e1739f684170805be7c3c1892c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83926413895848359354db0b4670b383",
            "placeholder": "​",
            "style": "IPY_MODEL_5c6ac315dc6a4f7fbc9b22ae97faf7ff",
            "value": "Epoch 1/10 [Train]: 100%"
          }
        },
        "4f5d7f1e600144e48bf55556ee5b67fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84430fa93be7492f93d162011a7923a8",
            "max": 63,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f711f4da4b82449daece525a103fe0e5",
            "value": 63
          }
        },
        "5a2c7d9134cf4258861c79b7e2728384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfcb0f038c1241bb93438f9df5922427",
            "placeholder": "​",
            "style": "IPY_MODEL_0842395f60734496a5c2e3786670160c",
            "value": " 63/63 [00:26&lt;00:00,  2.32it/s, loss=-0]"
          }
        },
        "0607bc71a42e45d3be2dfbafd47a5d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83926413895848359354db0b4670b383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6ac315dc6a4f7fbc9b22ae97faf7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84430fa93be7492f93d162011a7923a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f711f4da4b82449daece525a103fe0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfcb0f038c1241bb93438f9df5922427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0842395f60734496a5c2e3786670160c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c5f5c29623f4739a27d1e21c629e5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e275b0daf964fb398f92432d7a39657",
              "IPY_MODEL_8b3a3f70c6204fc3bfc2773ca0595a3c",
              "IPY_MODEL_d17f2b29aaa8452195c51cbba3b518eb"
            ],
            "layout": "IPY_MODEL_15e51adc208f4131a2217f7451941a39"
          }
        },
        "8e275b0daf964fb398f92432d7a39657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d4c07dadfeb44e398a7ea52e24664d4",
            "placeholder": "​",
            "style": "IPY_MODEL_179203cdd5e14339933b40038817fb28",
            "value": "Epoch 1/10 [Val]:   0%"
          }
        },
        "8b3a3f70c6204fc3bfc2773ca0595a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad22b17a8ffe4cc6a28dd64302949be2",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7328027147f943f18fb354c97dd7653f",
            "value": 0
          }
        },
        "d17f2b29aaa8452195c51cbba3b518eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_302de9c0231e48c2b3ef8dd5428f52ba",
            "placeholder": "​",
            "style": "IPY_MODEL_bbf1becae9b34f09b6b9df4bb9babb74",
            "value": " 0/14 [00:00&lt;?, ?it/s]"
          }
        },
        "15e51adc208f4131a2217f7451941a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d4c07dadfeb44e398a7ea52e24664d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179203cdd5e14339933b40038817fb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad22b17a8ffe4cc6a28dd64302949be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7328027147f943f18fb354c97dd7653f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "302de9c0231e48c2b3ef8dd5428f52ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf1becae9b34f09b6b9df4bb9babb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}